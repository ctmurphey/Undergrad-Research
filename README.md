# Undergrad-Research

A select collection of the work I did in my undergraduate at the University of Illinois, resulting in the research paper [Murphey, et. al., (2020)](https://arxiv.org/abs/2012.06552) which would go on to be published in [*Monthly Notices of the Royal Astronomical Society*](https://academic.oup.com/mnras/article-abstract/507/1/927/6330468?redirectedFrom=fulltext). The work centered around modeling both what fraction of supernovae (SNe) in the Milky Way we are likely to see and where to see it, building off of the models in [Adams, et. al., (2013)](https://arxiv.org/pdf/1306.0559.pdf).

## Setup
We start with the double exponential distribution given in the Adams paper, modelling both core-collapse supernove (CCSNe) and Type-Ia supernovae(IaSNe) individually, as well as dust. We use 3D density distributions following these double exponential models (see Murphey, et. al. for equations as GitHub doesn't support them). We then use two different algorithms we developed to then calculate the probability of seeing any given supernovae and where on the sky in their own way.
## Integration
The integration method we use takes an array of signlines across the whole sky and calculates the distance from Earth along each sightline in which the given type of supernova is still visible. It does this by taking 10 parsec steps along the sightlines until the amount of light extinction is greater than the difference between the SN's absolute magnitude and the dimmest visible magnitude of the human eye. The collection of coordinates and points then become a surface on which to integrate in 3 dimensions on along. By integrating outward along the signlines first, we get the Probability Density Function (PDF) representing the probability density map that shows where in the sky we are most likely to see supernovae. Integrating across this map then gives us the total probability of seeing any type of supernova when such type occurs. While these are less prone to error and random noise than the Monte-Carlo method, they suffer from being extremely slow for their resolution. This lack of resolution is the main reason why the plots it generates do not appear in the paper, and were mostly used to make sure the Monte Carlo methods generated accurate numbers.

### probwithsight. py
This program is the main integration program. It follows the algorithm above to calculate the probability of seeing a given type of supernova and plot a zoomed in map of the PDF (very little occurs outside the Galactic Plane). It takes several hours to run at any discrenable resolution (>900 pts) with a reasonable precision (sightline steps of 10 pc), so it was run only a couple times at medium resolution then used as a check for the faster Monte Carlo programs.
![Alt text](./Images/Integration_adams.png)

## Monte Carlo
Each Monte Carlo Simulation works as follows: First, a set on 3*n* random values between 0 and 1, representing the random variable for the *r*, *theta*, and *z* coordinates for *n* simulated supernovae. These points are then scaled to follow their probability distributions, multiplying the theta variable by 2pi and performing a root finding algotrithm to scale the r and z. Each collection of (*r*, *z*, theta) is then individually analyzed to see if it would be seen from earth, located at (8.5kpc, 20pc, 0). While this method has larger variance and is more susceptible to random noise than the integration method, it has multiple benefits. The first is that it runs significantly faster, allowing us to shrink the varience down by simulating >1,000,000 points. Secondly, it is more easly applicable to similar questions, like "How does the probabilty change if we adjust the dimmest magnitude we can see?" 

### mc_sn.py
This program makes four subplots from a collection of 100,000 simulated SN points. The first is an rotatable 3D visualization of all of the supernovae. The visible ones are colored blue and Sun is added in as a reference point. The second is a 2-D plot of their view from Earth in Galactic coordinates. The third and fourth are latitude and longitude histograms of all of the points.
![Alt text](./Images/montecarlo_subplots.png "mc_sn.png")

### mc_map.py
This code simulates 20,000 Sne and follows the Monte Carlo algorithm to generate a 2D PDF map. The galactic coordinates of the visible SNe are then converted into their Galactic coordinates and made into a PDF using the Gaussian KDE in scipy.stats. The 2D maps in Murphey, et. al. are almost all generated via this program.
![Alt text](./Images/50K_CC_K_map_smooth.png)

### V_Fraction_both_types.py
This code models how the probability of seeing a supernova of either type changes as the visibility thresholds change. The maps were made using the maximum absolute magnitude, but the event is only that bright instantaneously. In order to actually be seen, though, it needs to be visible for weeks or even months. In our paper we introduced the idea of "sustained luminosity", the dimmest magnitude of the event over a period of time to account for that. The plot this code generates shows not only how the probability changes as visibility changes, but also how this sustained luminosity changes. It does this by running the agorithm across a range of both limiting apparent magnitudes and absolute magnitudes corresponding to the sustained luminosities and counting the fraction that remain visible in each of these combinations.
![Alt text](./Images/vis_vs_mag_both.png)